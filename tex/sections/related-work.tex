\section{Related work}\label{sec:related-work}

\gls{nlp} algorithms have been integrated into robotics systems for a myriad of applications, ranging from control of industrial robotic arms \cite{Akan2011,Watanabe2006} and mobile robots \cite{Matuszek2013} to complex interaction with humanoid systems using a combination of voice, text and image perception analysis \cite{Neo2008,Barabas2012}. For the voice and textual teaching, the objects names and relations can be identified using \gls{ner} algorithms \cite{Leon2014,Dlugolinsky2013}. This type of approach usually relies on syntactic and semantic parsing of the text and also in machine learning algorithms \cite{Ekbal2012} (such as \glspl{svm}, \glspl{hmm} and \glspl{crf}) in order to be able to recognize previously unseen object names. It may present some challenges \cite{Ratinov2009}, but this methodology can achieve multilingual entity recognition \cite{Rami2014} if language agnostic attributes are used. Other complementary techniques, such as gazetteers, can improve overall recognition by providing a list of known entities that can be used for exact / partial string matching. This might be a suitable approach when we have extensive and representative entity lists and we are not expecting the text we are going to annotate to have significant new entities. Otherwise, the gazetteers might increase the number of false negatives for unseen entities. This problem might be overcome using the approaches introduced in \cite{Smith2006}, in which the gazetteer features are normalized and the text tagging uses two \gls{crf} models (one trained with the gazetteer features and another without) that are later combined with a logarithmic opinion pool. This is similar to a mixture model, but uses a weighted multiplicative combination of models instead of a weighted additive combination.

Advanced applications of \gls{nlp} algorithms include the teaching of assembly operations to robot arm manipulation systems by human operators. The JAST robot presented in \cite{Rickert2007} was implemented using a multi-agent system capable of learning assembly operations by interpreting human voice commands along with their gestures and gaze. The speech recognition system uses a \gls{ccg} and a semantics module to analyze if the operator is making statements for teaching, asking for information or giving answers to previous questions made by the robot. The vision system besides tracking the hands and gaze of the operator to perform a better speech analysis, it also recognizes the assembly objects within the robot workspace using template matching techniques.

Another example of usage of \gls{nlp} methods in an industrial scenario is presented in \cite{Stenmark2013}, in which it is used a multi-lingual statistical semantic parser to extract assembly operations from natural language sentences given by remote operators. The system was developed using a client-server architecture, containing a natural language parser, a \gls{kif} and an engineering system. The parser finds predicates with their respective arguments in sentences and establishes coreference chains. The \gls{kif} contains ontologies and semantically annotated skills that are used for filtering the predicates and return only the ones relevant for assembly operations. Lastly, the engineering system is a high level programming interface that uses the predicates found by the parser to select the appropriate skills for assembly while also matching the predicates arguments with the knowledge database in order to identify the objects and analyze in which branch of the assembly tree they must be inserted for achieving proper assembly order.

Besides voice and textual input from humans, the assembly information can also be retrieved from online web pages or knowledge repositories. The system proposed in \cite{Tenorth2010} can extract the assembly graph by performing a syntactic and semantic analysis using a \gls{pcfg} parser and a \gls{pos} tagger followed by word sense retrieval and disambiguation using the WordNet database and the Cyc ontology. After having a preliminary assembly plan, it is executed in simulation to perform a high level validation and also to allow the optimization of the robot movements. If ambiguous or missing information is detected, the system tries to generate a valid assembly plan by analyzing the objects' environment, assembly context and also similar operations stored in its knowledge base.

Named entity recognition can also be useful to identify key information from mission operation orders given to operators of robotics systems, such as \glspl{uav}. Highlighting entities such as persons, times, locations, coordinates, targets and organizations allows the human operators to extract the necessary mission information faster. Moreover, in the future it might even be possible to have the robotic system autonomously extract all the required information to carry on the mission without human assistance. The system introduced in \cite{Chesworth2016} was the first step towards this goal, and it was able to extract named entities from textual documents using \glspl{crf} statistical models that relied on features such as word lists, regular expressions, prefixes / sufixes, word case and also unigram / bigram / trigrams models. The evaluation of the \gls{ner} system was performed using metrics such as precision, recall and accuracy and used 9-fold cross validation for having a rotating train / test dataset in order to avoid model over-fitting.

Several datasets for \gls{ner} have been presented over the years for news and tweets \cite{Dojchinovski2013,Roder2014}. This paper aims to provide a new dataset for evaluating \gls{ner} systems with a corpus containing a diverse range of assembly operations for small complex objects (alternators, gearboxes and engines) written in a language discourse that ranges from professional to informal. Moreover, we provide a detailed analysis of the fine tuning of the Stanford \gls{ner} system for this corpus, which achieved 89.91\% precision, 83.51\% recall and 84.69\% F1. As is stated in \cite{Tkachenko2012}, the proper selection of the \gls{crf} training features for a given corpus can have a significant effect on the entity recognition performance. For example, simple token level training of \glspl{crf} leads to poor performance, but if text features such as word prefix / suffix / shape, ortographic / morphological clues, along with word / phrasal clustering and \gls{pos} tags are used, this can result in a \gls{crf} language model that can be very effective on recognizing the intended entities. Moreover, the performance can be improved even further if gazetteers and external knowledge databases are used.
